{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Day 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the concept of Word Embedding uses the concept of one hot representation \n",
    "\n",
    "# in the concept of one hot representation we usually convert a word in the form of vector on the basis of some feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In keras we have a library called as  one-hot which will try to convert a word in a vector based on the vocablury size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg after one_hot representation \n",
    "\n",
    "# Boy is Good will be --> [2000,4000,5000]\n",
    "\n",
    "# where 2000 , 4000 , 5000 are the index numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will pass the whole value with the embedding layer\n",
    "\n",
    "# embedding layer main task is to convert these words into some vector representation\n",
    "\n",
    "# in the embedding layer we need to pass the number of dimenions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow > 2.0\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a sentence\n",
    "\n",
    "sentences = ['This is Arsh Mishra',\n",
    "            'This is Divyansh Sinha',\n",
    "            'Both are cool ',\n",
    "            'Lets hope for the best',\n",
    "            'Bye Friends see u next time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is Arsh Mishra', 'This is Divyansh Sinha', 'Both are cool ', 'Lets hope for the best', 'Bye Friends see u next time']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the vocablury size\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_representation = [one_hot(word,vocab_size) for word in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8758, 9614, 4933, 8191], [8758, 9614, 4244, 2940], [8512, 3836, 4381], [6597, 9583, 269, 8967, 7404], [8250, 286, 7148, 322, 3380, 5745]]\n"
     ]
    }
   ],
   "source": [
    "print(onehot_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are watching the one hot representation of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding representation\n",
    "\n",
    "#importing the libraries for the above\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenever we want to pass anything to the embedding layers then all the sentences should have the same number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so for that we are using the pad - sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length = 10\n",
    "embedding_docs = pad_sequences(onehot_representation,padding='pre',maxlen = sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0 8758 9614 4933 8191]\n",
      " [   0    0    0    0    0    0 8758 9614 4244 2940]\n",
      " [   0    0    0    0    0    0    0 8512 3836 4381]\n",
      " [   0    0    0    0    0 6597 9583  269 8967 7404]\n",
      " [   0    0    0    0 8250  286 7148  322 3380 5745]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here as we can see that the first sentece was this is arsh mishra and the second sentence was this is divyansh sinha\n",
    "# this is -> both words are having the same value in the vectors representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the dimensions\n",
    "dimension = 15\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,dimension,input_length = sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 15)            150000    \n",
      "=================================================================\n",
      "Total params: 150,000\n",
      "Trainable params: 150,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.00324432 -0.04134851  0.00662643  0.03975799 -0.01280255\n",
      "   -0.03954917 -0.01490693  0.02824805 -0.00090345  0.01001809\n",
      "   -0.02056046  0.01309348 -0.01495305 -0.01826748  0.00888636]\n",
      "  [ 0.01475092 -0.03002152 -0.02656425  0.04426936  0.009921\n",
      "    0.00768744 -0.004826   -0.04319961 -0.008645   -0.04957744\n",
      "    0.02525232 -0.03918879 -0.04175582 -0.03361811 -0.03969145]\n",
      "  [ 0.02445701 -0.02868937  0.02672884 -0.00735216 -0.0089158\n",
      "    0.01433737 -0.02772442  0.00216744  0.03750279 -0.0114357\n",
      "    0.03863622  0.00267041  0.04972987 -0.01321205  0.02508261]\n",
      "  [-0.01652963 -0.00778501 -0.04608274 -0.01394336  0.02916444\n",
      "   -0.04160887  0.02911557 -0.03238972 -0.03562155  0.03720732\n",
      "   -0.00131121  0.02990282 -0.00272911  0.01970846  0.04947065]]\n",
      "\n",
      " [[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.00324432 -0.04134851  0.00662643  0.03975799 -0.01280255\n",
      "   -0.03954917 -0.01490693  0.02824805 -0.00090345  0.01001809\n",
      "   -0.02056046  0.01309348 -0.01495305 -0.01826748  0.00888636]\n",
      "  [ 0.01475092 -0.03002152 -0.02656425  0.04426936  0.009921\n",
      "    0.00768744 -0.004826   -0.04319961 -0.008645   -0.04957744\n",
      "    0.02525232 -0.03918879 -0.04175582 -0.03361811 -0.03969145]\n",
      "  [-0.04828763 -0.02586317 -0.00265223  0.0128204  -0.02824267\n",
      "    0.01388032 -0.02538773 -0.01439134 -0.03172507 -0.03485788\n",
      "    0.01150222 -0.04170815 -0.04871575 -0.01240023 -0.04856713]\n",
      "  [-0.03696419  0.01058447 -0.0226248  -0.00894145  0.04043708\n",
      "   -0.03034871 -0.04957513 -0.00019302  0.03528238 -0.00173516\n",
      "   -0.04530875  0.02266166  0.04682697 -0.01829909  0.03559109]]\n",
      "\n",
      " [[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01949583 -0.00433931  0.02790092  0.0162334   0.01921004\n",
      "   -0.02568225  0.02921187 -0.04323769 -0.03050026  0.02893461\n",
      "    0.01725963 -0.01160364  0.03077603 -0.01935847  0.01257229]\n",
      "  [ 0.00813442  0.00352365  0.00243836  0.00209911  0.01164764\n",
      "   -0.00881721 -0.0281495  -0.03285503  0.0067047  -0.00466186\n",
      "   -0.0076861  -0.01428483  0.00749469  0.02489394  0.0336527 ]\n",
      "  [ 0.01675165  0.03187695 -0.0310842  -0.00322936 -0.04793551\n",
      "   -0.00644506  0.02167531  0.0479739  -0.04895128  0.04599834\n",
      "   -0.0274896   0.00998981  0.03900624 -0.03348341  0.00530982]]\n",
      "\n",
      " [[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.00423989  0.00196387 -0.01559234 -0.01604808 -0.02699826\n",
      "    0.00933237  0.04474739 -0.01979812  0.01878861 -0.01978134\n",
      "    0.0351851   0.00795401 -0.01967678 -0.02166268 -0.04400096]\n",
      "  [-0.04665078  0.02399316  0.01131604  0.040458    0.03079504\n",
      "    0.02524266  0.03993913 -0.01341268  0.03126142 -0.0002389\n",
      "    0.04543889  0.03697333  0.0290674   0.03810556 -0.04255257]\n",
      "  [ 0.02785636  0.00664456 -0.00053523  0.03796115  0.02175683\n",
      "    0.04818017  0.02537725 -0.04394164 -0.03842771  0.03425899\n",
      "    0.01883909 -0.0205426  -0.02268361 -0.04993938 -0.04094697]\n",
      "  [-0.03044494  0.0067472   0.02653496 -0.01633739 -0.02830337\n",
      "    0.02947013  0.04789339 -0.00669986 -0.03231993  0.02939475\n",
      "    0.01582785  0.04504264 -0.0098763   0.0173174   0.0153697 ]\n",
      "  [-0.02647991  0.00471961  0.03018271  0.03096476 -0.0222538\n",
      "   -0.01441228 -0.04827085 -0.02142131  0.02156183 -0.03797302\n",
      "    0.0393321  -0.008398    0.01367671  0.02342675 -0.03084477]]\n",
      "\n",
      " [[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177\n",
      "    0.01538659 -0.0312767  -0.00828079  0.01333589  0.01900805\n",
      "   -0.01590142 -0.02361814 -0.0188328   0.01864443  0.01773231]\n",
      "  [-0.01795418 -0.02372792  0.04916206 -0.03520621  0.01436566\n",
      "    0.01326055  0.0450488  -0.02538233  0.04941963  0.02482513\n",
      "    0.0376584  -0.03226733 -0.0494071  -0.02188596  0.0398202 ]\n",
      "  [ 0.00100208 -0.00776415  0.00914513 -0.0322245  -0.00662466\n",
      "   -0.00584728  0.03739494 -0.04442292 -0.04744801 -0.01811991\n",
      "    0.00413761 -0.01195874  0.03956357 -0.04514673  0.0326614 ]\n",
      "  [ 0.00907719  0.03131267 -0.0141055   0.00461753  0.02914185\n",
      "    0.04146521  0.04711192 -0.02268429 -0.03258361  0.03658349\n",
      "    0.04463789  0.01406416 -0.00184574 -0.03940407 -0.01395714]\n",
      "  [-0.01429965  0.03832882 -0.03158335  0.03914445  0.00441154\n",
      "   -0.00622547 -0.04888372 -0.00601029  0.0493614  -0.02683685\n",
      "    0.00120182  0.00884038 -0.04025421 -0.00400261  0.0188883 ]\n",
      "  [-0.00931646  0.04746466  0.00905385 -0.03879684 -0.02211319\n",
      "    0.01274623 -0.00574902  0.02648352  0.01173985 -0.02283537\n",
      "    0.04410343 -0.03790059  0.03721159  0.02643968 -0.04389726]\n",
      "  [-0.04711488  0.02342853  0.03352937 -0.04095539 -0.03353043\n",
      "   -0.04822803 -0.03706522  0.0439701  -0.00962592 -0.02627034\n",
      "   -0.02628447  0.03037829 -0.02272906  0.00142318 -0.03901981]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedding_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.01682502 -0.00459906  0.02913715  0.03771733 -0.02473177  0.01538659\n",
      "  -0.0312767  -0.00828079  0.01333589  0.01900805 -0.01590142 -0.02361814\n",
      "  -0.0188328   0.01864443  0.01773231]\n",
      " [-0.00324432 -0.04134851  0.00662643  0.03975799 -0.01280255 -0.03954917\n",
      "  -0.01490693  0.02824805 -0.00090345  0.01001809 -0.02056046  0.01309348\n",
      "  -0.01495305 -0.01826748  0.00888636]\n",
      " [ 0.01475092 -0.03002152 -0.02656425  0.04426936  0.009921    0.00768744\n",
      "  -0.004826   -0.04319961 -0.008645   -0.04957744  0.02525232 -0.03918879\n",
      "  -0.04175582 -0.03361811 -0.03969145]\n",
      " [ 0.02445701 -0.02868937  0.02672884 -0.00735216 -0.0089158   0.01433737\n",
      "  -0.02772442  0.00216744  0.03750279 -0.0114357   0.03863622  0.00267041\n",
      "   0.04972987 -0.01321205  0.02508261]\n",
      " [-0.01652963 -0.00778501 -0.04608274 -0.01394336  0.02916444 -0.04160887\n",
      "   0.02911557 -0.03238972 -0.03562155  0.03720732 -0.00131121  0.02990282\n",
      "  -0.00272911  0.01970846  0.04947065]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedding_docs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0, 8758, 9614, 4933, 8191])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word we can see a vector assigned to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
